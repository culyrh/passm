# YOLOv8-Face + ArcFace ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ

import cv2
import torch
import numpy as np
from ultralytics import YOLO
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import time
import logging
from typing import List, Dict, Any, Optional, Tuple
import os
from pathlib import Path
import pickle
import dlib
from scipy.spatial.distance import cosine

logger = logging.getLogger(__name__)

class ArcFaceModel(nn.Module):
    """ArcFace ëª¨ë¸ (ê°„ë‹¨í•œ ResNet50 ê¸°ë°˜ êµ¬í˜„)"""
    
    def __init__(self, embedding_size=512, num_classes=None):
        super(ArcFaceModel, self).__init__()
        self.embedding_size = embedding_size
        
        # ResNet50 ê¸°ë°˜ ë°±ë³¸ (ê°„ë‹¨í™”)
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        
        # ResNet ë¸”ë¡ë“¤ (ê°„ë‹¨í™”)
        self.layer1 = self._make_layer(64, 128, 2)
        self.layer2 = self._make_layer(128, 256, 2)
        self.layer3 = self._make_layer(256, 512, 2)
        
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, embedding_size)
        
        # ArcFace í—¤ë“œ (í›ˆë ¨ìš©, ì¶”ë¡ ì‹œì—ëŠ” ì‚¬ìš© ì•ˆí•¨)
        if num_classes:
            self.arc_head = ArcMarginProduct(embedding_size, num_classes)
    
    def _make_layer(self, in_channels, out_channels, stride):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, stride, 1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, 1, 1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        
        # L2 ì •ê·œí™” (ì¤‘ìš”!)
        x = F.normalize(x, p=2, dim=1)
        
        return x

class ArcMarginProduct(nn.Module):
    """ArcFace ì†ì‹¤ì„ ìœ„í•œ ë§ˆì§„ ê³±ì…ˆ ë ˆì´ì–´"""
    
    def __init__(self, in_features, out_features, s=30.0, m=0.50):
        super(ArcMarginProduct, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.s = s
        self.m = m
        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))
        nn.init.xavier_uniform_(self.weight)
    
    def forward(self, input, label=None):
        cosine = F.linear(F.normalize(input), F.normalize(self.weight))
        
        if label is None:
            return cosine * self.s
        
        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))
        phi = cosine * np.cos(self.m) - sine * np.sin(self.m)
        
        one_hot = torch.zeros(cosine.size()).to(input.device)
        one_hot.scatter_(1, label.view(-1, 1).long(), 1)
        
        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)
        output *= self.s
        
        return output

class YOLOv8ArcFace:
    """YOLOv8-Face + ArcFace í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 yolo_model_path: str = "yolov8n-face.pt",
                 arcface_model_path: Optional[str] = None,
                 device: str = 'cpu'):
        """
        Args:
            yolo_model_path: YOLOv8-Face ëª¨ë¸ ê²½ë¡œ
            arcface_model_path: ArcFace ëª¨ë¸ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ ëª¨ë¸)
            device: ì—°ì‚° ì¥ì¹˜
        """
        self.device = device
        self.confidence_threshold = 0.5
        self.iou_threshold = 0.45
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_yolo_model(yolo_model_path)
        self.load_arcface_model(arcface_model_path)
        
        # ì–¼êµ´ ì •ë ¬ìš© dlib (ArcFaceì˜ í•µì‹¬ íŠ¹ì§•)
        self.load_face_alignment()
        
        # ì‚¬ìš©ì ë°ì´í„°
        self.user_embeddings = {}
        self.user_names = []
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ArcFace í‘œì¤€)
        self.transform = transforms.Compose([
            transforms.Resize((112, 112)),  # ArcFace í‘œì¤€ í¬ê¸°
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        
        logger.info("âœ… YOLOv8-Face + ArcFace ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_yolo_model(self, model_path: str):
        """YOLOv8-Face ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info(f"ğŸ“ YOLOv8-Face ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
            
            if not os.path.exists(model_path):
                logger.warning(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ. ê¸°ë³¸ YOLOv8n ë‹¤ìš´ë¡œë“œ")
                self.yolo_model = YOLO("yolov8n.pt")
            else:
                self.yolo_model = YOLO(model_path)
            
            self.yolo_model.to(self.device)
            
            # ì›Œë°ì—…
            dummy_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            _ = self.yolo_model(dummy_img, verbose=False)
            
            logger.info("âœ… YOLOv8-Face ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ YOLOv8 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.yolo_model = None
    
    def load_arcface_model(self, model_path: Optional[str]):
        """ArcFace ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info("ğŸ“ ArcFace ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            self.arcface_model = ArcFaceModel(embedding_size=512)
            self.arcface_model.to(self.device)
            self.arcface_model.eval()
            
            # ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ê°€ ìˆë‹¤ë©´ ë¡œë“œ
            if model_path and os.path.exists(model_path):
                checkpoint = torch.load(model_path, map_location=self.device)
                self.arcface_model.load_state_dict(checkpoint)
                logger.info(f"âœ… ì‚¬ì „ í›ˆë ¨ëœ ArcFace ê°€ì¤‘ì¹˜ ë¡œë“œ: {model_path}")
            else:
                logger.warning("âš ï¸ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì—†ìŒ. ëœë¤ ì´ˆê¸°í™”ëœ ëª¨ë¸ ì‚¬ìš©")
            
            logger.info("âœ… ArcFace ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ArcFace ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.arcface_model = None
    
    def load_face_alignment(self):
        """ì–¼êµ´ ì •ë ¬ìš© dlib ë¡œë“œ (ArcFaceì˜ í•µì‹¬ ê¸°ëŠ¥)"""
        try:
            logger.info("ğŸ“ ì–¼êµ´ ì •ë ¬ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        
            # dlib ì–¼êµ´ ê²€ì¶œê¸°
            self.face_detector = dlib.get_frontal_face_detector()
        
            # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
            import os
            current_dir = os.path.dirname(__file__)
            predictor_path = os.path.join(current_dir, "models", "shape_predictor_68_face_landmarks.dat")
        
            # ê²½ë¡œ í™•ì¸ ë¡œê·¸ ì¶”ê°€
            logger.info(f"ğŸ” ëœë“œë§ˆí¬ ëª¨ë¸ ê²½ë¡œ: {predictor_path}")
            logger.info(f"ğŸ” íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(predictor_path)}")
        
            if os.path.exists(predictor_path):
                self.shape_predictor = dlib.shape_predictor(predictor_path)
                logger.info("âœ… 68ì  ëœë“œë§ˆí¬ ì˜ˆì¸¡ê¸° ë¡œë“œ")
            else:
                # 5ì  ëª¨ë¸ë„ ì‹œë„
                predictor_path_5 = os.path.join(current_dir, "models", "shape_predictor_5_face_landmarks.dat")
                if os.path.exists(predictor_path_5):
                    self.shape_predictor = dlib.shape_predictor(predictor_path_5)
                    logger.info("âœ… 5ì  ëœë“œë§ˆí¬ ì˜ˆì¸¡ê¸° ë¡œë“œ")
                else:
                    logger.warning("âš ï¸ dlib ëœë“œë§ˆí¬ ì˜ˆì¸¡ê¸° ì—†ìŒ. ì •ë ¬ ê¸°ëŠ¥ ë¹„í™œì„±í™”")
                    self.shape_predictor = None
                
        except Exception as e:
            logger.error(f"âŒ ì–¼êµ´ ì •ë ¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.face_detector = None
            self.shape_predictor = None
    
    def detect_faces(self, image: np.ndarray) -> Tuple[List[Dict], float]:
        """YOLOv8-Faceë¡œ ì–¼êµ´ ê²€ì¶œ"""
        start_time = time.time()
        
        if self.yolo_model is None:
            return [], 0.0
        
        try:
            # YOLO ì¶”ë¡ 
            results = self.yolo_model(
                image,
                conf=self.confidence_threshold,
                iou=self.iou_threshold,
                verbose=False,
                device=self.device
            )
            
            faces = []
            
            if results and len(results) > 0:
                result = results[0]
                
                if result.boxes is not None:
                    boxes = result.boxes
                    
                    for box in boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = float(box.conf[0].cpu().numpy())
                        class_id = int(box.cls[0].cpu().numpy())
                        
                        # ì‚¬ëŒ/ì–¼êµ´ í´ë˜ìŠ¤ë§Œ í•„í„°ë§
                        class_name = self.yolo_model.names.get(class_id, "unknown")
                        if class_name.lower() in ['person', 'face', '0']:
                            
                            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì •ë¦¬
                            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                            
                            # ì´ë¯¸ì§€ ê²½ê³„ ì²´í¬
                            img_h, img_w = image.shape[:2]
                            x1 = max(0, x1)
                            y1 = max(0, y1)
                            x2 = min(img_w, x2)
                            y2 = min(img_h, y2)
                            
                            if x2 > x1 and y2 > y1:
                                face_info = {
                                    'bbox': [x1, y1, x2-x1, y2-y1],
                                    'confidence': confidence,
                                    'area': (x2-x1) * (y2-y1),
                                    'method': 'yolov8'
                                }
                                faces.append(face_info)
            
            # ë©´ì  ê¸°ì¤€ ì •ë ¬ (í° ì–¼êµ´ ìš°ì„ )
            faces.sort(key=lambda x: x['area'], reverse=True)
            
            processing_time = time.time() - start_time
            return faces, float(processing_time)
            
        except Exception as e:
            logger.error(f"âŒ YOLO ì–¼êµ´ ê²€ì¶œ ì˜¤ë¥˜: {e}")
            return [], float(time.time() - start_time)
    
    def align_face(self, image: np.ndarray, face_bbox: List[int]) -> np.ndarray:
        """
        ì–¼êµ´ ì •ë ¬ (ArcFaceì˜ í•µì‹¬ ê¸°ëŠ¥)
        - ì–¼êµ´ì„ ì •ë©´ìœ¼ë¡œ íšŒì „
        - ëˆˆ, ì½”, ì…ì˜ ìœ„ì¹˜ë¥¼ í‘œì¤€í™”
        """
        try:
            x, y, w, h = face_bbox
            face_region = image[y:y+h, x:x+w]
            
            if self.face_detector is None or self.shape_predictor is None:
                # ì •ë ¬ ë¶ˆê°€ëŠ¥í•˜ë©´ ë¦¬ì‚¬ì´ì¦ˆë§Œ
                return cv2.resize(face_region, (112, 112))
            
            # dlibìœ¼ë¡œ ëœë“œë§ˆí¬ ê²€ì¶œ
            gray = cv2.cvtColor(face_region, cv2.COLOR_BGR2GRAY)
            faces = self.face_detector(gray)
            
            if len(faces) == 0:
                return cv2.resize(face_region, (112, 112))
            
            # ì²« ë²ˆì§¸ ì–¼êµ´ì˜ ëœë“œë§ˆí¬
            landmarks = self.shape_predictor(gray, faces[0])
            
            # ëœë“œë§ˆí¬ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            points = []
            for n in range(landmarks.num_parts):
                points.append([landmarks.part(n).x, landmarks.part(n).y])
            points = np.array(points)
            
            # ëˆˆ ì¤‘ì‹¬ì  ê³„ì‚° (ì •ë ¬ ê¸°ì¤€ì )
            if len(points) >= 68:  # 68ì  ëª¨ë¸
                left_eye = points[36:42].mean(axis=0)
                right_eye = points[42:48].mean(axis=0)
            elif len(points) >= 5:  # 5ì  ëª¨ë¸
                left_eye = points[0]
                right_eye = points[1]
            else:
                return cv2.resize(face_region, (112, 112))
            
            # íšŒì „ ê°ë„ ê³„ì‚°
            dy = right_eye[1] - left_eye[1]
            dx = right_eye[0] - left_eye[0]
            angle = np.degrees(np.arctan2(dy, dx))
            
            # ë‘ ëˆˆ ì‚¬ì´ì˜ ê±°ë¦¬
            eye_distance = np.linalg.norm(right_eye - left_eye)
            
            # ì–¼êµ´ ì¤‘ì‹¬ì 
            eye_center = ((left_eye[0] + right_eye[0]) // 2, 
                         (left_eye[1] + right_eye[1]) // 2)
            
            # íšŒì „ ë° í¬ê¸° ì¡°ì •ì„ ìœ„í•œ ë³€í™˜ í–‰ë ¬
            desired_eye_distance = 35  # ëª©í‘œ ëˆˆ ê°„ê²© (í”½ì…€)
            scale = desired_eye_distance / eye_distance
            
            # íšŒì „ ë³€í™˜
            M = cv2.getRotationMatrix2D(eye_center, angle, scale)
            
            # ì´ë™ ë³€í™˜ (ì–¼êµ´ì„ ì¤‘ì•™ìœ¼ë¡œ)
            tX = 112 * 0.5
            tY = 112 * 0.35  # ì•½ê°„ ìœ„ìª½ì— ìœ„ì¹˜
            M[0, 2] += (tX - eye_center[0])
            M[1, 2] += (tY - eye_center[1])
            
            # ë³€í™˜ ì ìš©
            aligned_face = cv2.warpAffine(face_region, M, (112, 112), 
                                        flags=cv2.INTER_CUBIC)
            
            return aligned_face
            
        except Exception as e:
            logger.error(f"âŒ ì–¼êµ´ ì •ë ¬ ì˜¤ë¥˜: {e}")
            # ì •ë ¬ ì‹¤íŒ¨ì‹œ ë‹¨ìˆœ ë¦¬ì‚¬ì´ì¦ˆ
            try:
                x, y, w, h = face_bbox
                face_region = image[y:y+h, x:x+w]
                return cv2.resize(face_region, (112, 112))
            except:
                return np.zeros((112, 112, 3), dtype=np.uint8)
    
    def extract_face_embedding(self, image: np.ndarray, face_bbox: List[int]) -> np.ndarray:
        """ArcFaceë¡œ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ (ì •ë ¬ í¬í•¨)"""
        if self.arcface_model is None:
            return np.array([])
        
        try:
            # 1. ì–¼êµ´ ì •ë ¬ (ArcFaceì˜ í•µì‹¬!)
            aligned_face = self.align_face(image, face_bbox)
            
            # 2. BGR -> RGB ë³€í™˜
            face_rgb = cv2.cvtColor(aligned_face, cv2.COLOR_BGR2RGB)
            face_pil = Image.fromarray(face_rgb)
            
            # 3. ì „ì²˜ë¦¬
            face_tensor = self.transform(face_pil).unsqueeze(0).to(self.device)
            
            # 4. ArcFace ì„ë² ë”© ì¶”ì¶œ
            with torch.no_grad():
                embedding = self.arcface_model(face_tensor)
                embedding = embedding.cpu().numpy().flatten()
            
            return embedding
            
        except Exception as e:
            logger.error(f"âŒ ArcFace ì„ë² ë”© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return np.array([])
    
    def load_user_database(self, users_dir: str = "data/users"):
        """ì‚¬ìš©ì ì–¼êµ´ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        try:
            if not os.path.exists(users_dir):
                logger.warning(f"ì‚¬ìš©ì ë°ì´í„° í´ë” ì—†ìŒ: {users_dir}")
                return
            
            self.user_embeddings = {}
            self.user_names = []
            
            for user_name in os.listdir(users_dir):
                user_path = os.path.join(users_dir, user_name)
                
                if os.path.isdir(user_path):
                    logger.info(f"ğŸ“„ {user_name} ë°ì´í„° ë¡œë“œ ì¤‘...")
                    
                    user_embeddings_list = []
                    processed_count = 0
                    
                    for image_file in os.listdir(user_path):
                        if image_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                            image_path = os.path.join(user_path, image_file)
                            
                            try:
                                # ì´ë¯¸ì§€ ë¡œë“œ
                                image = cv2.imread(image_path)
                                if image is None:
                                    continue
                                
                                # ì–¼êµ´ ê²€ì¶œ
                                faces, _ = self.detect_faces(image)
                                
                                if faces:
                                    # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
                                    largest_face = max(faces, key=lambda x: x['area'])
                                    
                                    # ArcFace ì„ë² ë”© ì¶”ì¶œ (ì •ë ¬ í¬í•¨)
                                    embedding = self.extract_face_embedding(image, largest_face['bbox'])
                                    
                                    if len(embedding) > 0:
                                        user_embeddings_list.append(embedding)
                                        processed_count += 1
                                        
                            except Exception as e:
                                logger.warning(f"âš ï¸ {image_file} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                                continue
                    
                    if user_embeddings_list:
                        self.user_embeddings[user_name] = user_embeddings_list
                        self.user_names.append(user_name)
                        logger.info(f"âœ… {user_name}: {processed_count}ì¥ ì²˜ë¦¬ ì™„ë£Œ")
                    else:
                        logger.warning(f"âš ï¸ {user_name}: ì²˜ë¦¬ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ì—†ìŒ")
            
            logger.info(f"ğŸ¯ ì´ {len(self.user_names)}ëª…ì˜ ì‚¬ìš©ì ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            
            # ì„ë² ë”© ë°ì´í„° ì €ì¥
            self.save_embeddings()
            
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def save_embeddings(self, save_path: str = "data/arcface_embeddings.pkl"):
        """ì„ë² ë”© ë°ì´í„° ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            with open(save_path, 'wb') as f:
                pickle.dump({
                    'user_embeddings': self.user_embeddings,
                    'user_names': self.user_names
                }, f)
            logger.info(f"ğŸ’¾ ì„ë² ë”© ë°ì´í„° ì €ì¥: {save_path}")
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_embeddings(self, load_path: str = "data/arcface_embeddings.pkl"):
        """ì„ë² ë”© ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists(load_path):
                with open(load_path, 'rb') as f:
                    data = pickle.load(f)
                self.user_embeddings = data['user_embeddings']
                self.user_names = data['user_names']
                logger.info(f"ğŸ“‚ ì„ë² ë”© ë°ì´í„° ë¡œë“œ: {len(self.user_names)}ëª…")
                return True
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    
    def recognize_user(self, face_embedding: np.ndarray, threshold: float = 0.4) -> Dict:
        """
        ArcFace ì„ë² ë”©ìœ¼ë¡œ ì‚¬ìš©ì ì¸ì‹ - ìˆ˜ì •ëœ ë²„ì „
        """
        if len(self.user_embeddings) == 0:
            return {
                'recognized': False,
                'user_name': 'ë°ì´í„°ë² ì´ìŠ¤ ì—†ìŒ',
                'confidence': 0.0,
                'similarity': 0.0,
                'message': 'ë“±ë¡ëœ ì‚¬ìš©ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'
            }
    
        if len(face_embedding) == 0:
            return {
                'recognized': False,
                'user_name': 'íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨',
                'confidence': 0.0,
                'similarity': 0.0,
                'message': 'ì–¼êµ´ íŠ¹ì§•ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }
    
        try:
            # ì„ë² ë”© ì •ê·œí™”
            face_embedding = face_embedding.astype(np.float64)
            face_norm = np.linalg.norm(face_embedding)
            if face_norm > 0:
                face_embedding = face_embedding / face_norm
        
            best_distance = float('inf')
            best_user = None
            all_similarities = {}
        
            # ê° ì‚¬ìš©ìì™€ì˜ ê±°ë¦¬ ê³„ì‚°
            for user_name, embeddings_list in self.user_embeddings.items():
                distances = []
            
                for stored_embedding in embeddings_list:
                    # ì €ì¥ëœ ì„ë² ë”© ì •ê·œí™”
                    stored_embedding = stored_embedding.astype(np.float64)
                    stored_norm = np.linalg.norm(stored_embedding)
                    if stored_norm > 0:
                        stored_embedding = stored_embedding / stored_norm
                
                    # ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ëŒ€ì‹ )
                    distance = np.linalg.norm(face_embedding - stored_embedding)
                    distances.append(distance)
            
                if distances:
                    min_distance = min(distances)
                    # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (0~1 ë²”ìœ„)
                    similarity = max(0, 1 - min_distance / 2.0)
                    all_similarities[user_name] = similarity
                
                    if min_distance < best_distance:
                        best_distance = min_distance
                        best_user = user_name
        
            # ìµœì¢… ìœ ì‚¬ë„ ë° ì‹ ë¢°ë„
            best_similarity = max(0, 1 - best_distance / 2.0)
            confidence = best_similarity * 100
        
            # ì¸ì‹ ì„±ê³µ ì¡°ê±´: ìœ ì‚¬ë„ê°€ thresholdë³´ë‹¤ ë†’ê³ , ê±°ë¦¬ê°€ 1.2ë³´ë‹¤ ì‘ì„ ë•Œ
            if best_similarity > threshold and best_distance < 1.2:
                return {
                    'recognized': True,
                    'user_name': str(best_user),
                    'confidence': float(round(confidence, 2)),
                    'similarity': float(round(best_similarity, 4)),
                    'distance': float(round(best_distance, 4)),
                    'threshold': float(threshold),
                    'all_similarities': {k: float(round(v, 4)) for k, v in all_similarities.items()},
                    'message': f'{best_user} ì¸ì‹ ì„±ê³µ (ê±°ë¦¬ ê¸°ë°˜)',
                    'method': 'euclidean_distance'
                }
            else:
                return {
                    'recognized': False,
                    'user_name': 'ë¯¸ë“±ë¡ ì¸ë¬¼',
                    'confidence': float(round(confidence, 2)),
                    'similarity': float(round(best_similarity, 4)),
                    'distance': float(round(best_distance, 4)),
                    'threshold': float(threshold),
                    'best_match': str(best_user) if best_user else 'ë§¤ì¹­ ì—†ìŒ',
                    'all_similarities': {k: float(round(v, 4)) for k, v in all_similarities.items()},
                    'message': f'ê±°ë¦¬ {round(best_distance, 4)} > ì„ê³„ê°’, ìœ ì‚¬ë„ {round(best_similarity, 4)} < {threshold}',
                    'method': 'euclidean_distance'
                }
            
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ì¸ì‹ ì˜¤ë¥˜: {e}")
            return {
                'recognized': False,
                'user_name': 'ì¸ì‹ ì˜¤ë¥˜',
                'confidence': 0.0,
                'similarity': 0.0,
                'message': f'ì¸ì‹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }
    
    def process_image(self, image: np.ndarray) -> Dict:
        """
        ì „ì²´ ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        1. YOLOv8-Faceë¡œ ì–¼êµ´ ê²€ì¶œ
        2. ì–¼êµ´ ì •ë ¬ (ArcFace í•µì‹¬ ê¸°ëŠ¥)
        3. ArcFaceë¡œ ì„ë² ë”© ì¶”ì¶œ ë° ì¸ì‹
        """
        start_time = time.time()
        
        try:
            # 1. ì–¼êµ´ ê²€ì¶œ
            faces, detection_time = self.detect_faces(image)
            
            if not faces:
                return {
                    'success': False,
                    'faces_found': 0,
                    'message': 'ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
                    'performance': {
                        'detection_time': float(round(detection_time, 3)),
                        'total_time': float(round(time.time() - start_time, 3))
                    }
                }
            
            # 2. ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
            main_face = faces[0]
            
            # 3. ì–¼êµ´ ì •ë ¬ ì‹œê°„ ì¸¡ì •
            alignment_start = time.time()
            aligned_face = self.align_face(image, main_face['bbox'])
            alignment_time = time.time() - alignment_start
            
            # 4. ArcFace ì„ë² ë”© ì¶”ì¶œ
            embedding_start = time.time()
            face_embedding = self.extract_face_embedding(image, main_face['bbox'])
            embedding_time = time.time() - embedding_start
            
            # 5. ì‚¬ìš©ì ì¸ì‹
            recognition_start = time.time()
            recognition_result = self.recognize_user(face_embedding)
            recognition_time = time.time() - recognition_start
            
            total_time = time.time() - start_time
            
            # ê²°ê³¼ í†µí•©
            result = {
                'success': True,
                'faces_found': int(len(faces)),
                'main_face': {
                    **main_face,
                    **recognition_result,
                    'aligned': True  # ì •ë ¬ë˜ì—ˆìŒì„ í‘œì‹œ
                },
                'all_faces': faces,
                'performance': {
                    'detection_time': float(round(detection_time, 3)),
                    'alignment_time': float(round(alignment_time, 3)),
                    'embedding_time': float(round(embedding_time, 3)),
                    'recognition_time': float(round(recognition_time, 3)),
                    'total_time': float(round(total_time, 3))
                },
                'method': 'yolov8_arcface',
                'embedding_size': len(face_embedding),
                'features': {
                    'face_alignment': True,
                    'landmark_detection': self.shape_predictor is not None,
                    'cosine_similarity': True
                }
            }
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'faces_found': 0,
                'message': f'ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}',
                'performance': {
                    'total_time': float(round(time.time() - start_time, 3))
                }
            }
    
    def get_model_info(self) -> Dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            'system_type': 'yolov8_arcface',
            'detection_model': 'YOLOv8-Face',
            'recognition_model': 'ArcFace (512D)',
            'alignment_model': 'dlib landmarks',
            'device': self.device,
            'confidence_threshold': self.confidence_threshold,
            'iou_threshold': self.iou_threshold,
            'registered_users_count': len(self.user_names),
            'registered_users': self.user_names,
            'model_loaded': self.yolo_model is not None and self.arcface_model is not None,
            'yolo_loaded': self.yolo_model is not None,
            'arcface_loaded': self.arcface_model is not None,
            'alignment_loaded': self.shape_predictor is not None,
            'embedding_dimension': 512,
            'similarity_metric': 'cosine',
            'features': {
                'face_alignment': True,
                'landmark_standardization': True,
                'rotation_correction': True,
                'reference_point_unification': True
            }
        }