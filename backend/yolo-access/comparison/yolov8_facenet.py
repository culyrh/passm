# YOLOv8-Face + FaceNet ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ

import cv2
import torch
import numpy as np
from ultralytics import YOLO
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import time
import logging
from typing import List, Dict, Any, Optional, Tuple
import os
from pathlib import Path
import pickle

logger = logging.getLogger(__name__)

class InceptionResNetV1(nn.Module):
    """FaceNet ëª¨ë¸ (PyTorch êµ¬í˜„)"""
    
    def __init__(self, pretrained=True, classify=False, num_classes=None):
        super(InceptionResNetV1, self).__init__()
        self.classify = classify
        self.num_classes = num_classes
        
        # ê°„ë‹¨í•œ CNN êµ¬ì¡°ë¡œ ëŒ€ì²´ (ì‹¤ì œë¡œëŠ” ë³µì¡í•œ InceptionResNet êµ¬ì¡°)
        self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 2, 1)
        self.conv3 = nn.Conv2d(64, 128, 3, 2, 1)
        self.conv4 = nn.Conv2d(128, 256, 3, 2, 1)
        
        self.pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(256, 512)  # 512ì°¨ì› ì„ë² ë”©
        
        if classify:
            self.classifier = nn.Linear(512, num_classes)
    
    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = F.relu(self.conv3(x))
        x = F.relu(self.conv4(x))
        
        x = self.pool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        
        if self.classify:
            x = self.classifier(x)
        else:
            x = F.normalize(x, p=2, dim=1)  # L2 ì •ê·œí™”
        
        return x

class YOLOv8FaceNet:
    """YOLOv8-Face + FaceNet í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 yolo_model_path: str = "yolov8n-face.pt",
                 facenet_model_path: Optional[str] = None,
                 device: str = 'cpu'):
        """
        Args:
            yolo_model_path: YOLOv8-Face ëª¨ë¸ ê²½ë¡œ
            facenet_model_path: FaceNet ëª¨ë¸ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ ëª¨ë¸)
            device: ì—°ì‚° ì¥ì¹˜ ('cpu' ë˜ëŠ” 'cuda')
        """
        self.device = device
        self.confidence_threshold = 0.5
        self.iou_threshold = 0.45
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_yolo_model(yolo_model_path)
        self.load_facenet_model(facenet_model_path)
        
        # ì‚¬ìš©ì ë°ì´í„°
        self.user_embeddings = {}  # {user_name: [embedding_list]}
        self.user_names = []
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        self.transform = transforms.Compose([
            transforms.Resize((160, 160)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        
        logger.info("âœ… YOLOv8-Face + FaceNet ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_yolo_model(self, model_path: str):
        """YOLOv8-Face ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info(f"ğŸ“ YOLOv8-Face ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
            
            if not os.path.exists(model_path):
                logger.warning(f"ëª¨ë¸ íŒŒì¼ ì—†ìŒ. ê¸°ë³¸ YOLOv8n ë‹¤ìš´ë¡œë“œ: {model_path}")
                # YOLOv8-Face ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì¼ë°˜ YOLOv8ìœ¼ë¡œ ëŒ€ì²´
                self.yolo_model = YOLO("yolov8n.pt")
            else:
                self.yolo_model = YOLO(model_path)
            
            self.yolo_model.to(self.device)
            
            # ì›Œë°ì—…
            dummy_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            _ = self.yolo_model(dummy_img, verbose=False)
            
            logger.info("âœ… YOLOv8-Face ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ YOLOv8 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.yolo_model = None
    
    def load_facenet_model(self, model_path: Optional[str]):
        """FaceNet ëª¨ë¸ ë¡œë“œ"""
        try:
            logger.info("ğŸ“ FaceNet ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            self.facenet_model = InceptionResNetV1(pretrained=True, classify=False)
            self.facenet_model.to(self.device)
            self.facenet_model.eval()
            
            # ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ê°€ ìˆë‹¤ë©´ ë¡œë“œ
            if model_path and os.path.exists(model_path):
                checkpoint = torch.load(model_path, map_location=self.device)
                self.facenet_model.load_state_dict(checkpoint)
                logger.info(f"âœ… ì‚¬ì „ í›ˆë ¨ëœ FaceNet ê°€ì¤‘ì¹˜ ë¡œë“œ: {model_path}")
            else:
                logger.warning("âš ï¸ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì—†ìŒ. ëœë¤ ì´ˆê¸°í™”ëœ ëª¨ë¸ ì‚¬ìš©")
            
            logger.info("âœ… FaceNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ FaceNet ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.facenet_model = None
    
    def detect_faces(self, image: np.ndarray) -> Tuple[List[Dict], float]:
        """YOLOv8-Faceë¡œ ì–¼êµ´ ê²€ì¶œ"""
        start_time = time.time()
        
        if self.yolo_model is None:
            return [], 0.0
        
        try:
            # YOLO ì¶”ë¡ 
            results = self.yolo_model(
                image,
                conf=self.confidence_threshold,
                iou=self.iou_threshold,
                verbose=False,
                device=self.device
            )
            
            faces = []
            
            if results and len(results) > 0:
                result = results[0]
                
                if result.boxes is not None:
                    boxes = result.boxes
                    
                    for box in boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = float(box.conf[0].cpu().numpy())
                        class_id = int(box.cls[0].cpu().numpy())
                        
                        # ì‚¬ëŒ/ì–¼êµ´ í´ë˜ìŠ¤ë§Œ í•„í„°ë§
                        class_name = self.yolo_model.names.get(class_id, "unknown")
                        if class_name.lower() in ['person', 'face', '0']:
                            
                            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì •ë¦¬
                            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                            w, h = x2 - x1, y2 - y1
                            
                            # ì´ë¯¸ì§€ ê²½ê³„ ì²´í¬
                            img_h, img_w = image.shape[:2]
                            x1 = max(0, x1)
                            y1 = max(0, y1)
                            x2 = min(img_w, x2)
                            y2 = min(img_h, y2)
                            
                            if x2 > x1 and y2 > y1:
                                face_info = {
                                    'bbox': [x1, y1, x2-x1, y2-y1],
                                    'confidence': confidence,
                                    'area': (x2-x1) * (y2-y1),
                                    'method': 'yolov8'
                                }
                                faces.append(face_info)
            
            # ë©´ì  ê¸°ì¤€ ì •ë ¬ (í° ì–¼êµ´ ìš°ì„ )
            faces.sort(key=lambda x: x['area'], reverse=True)
            
            processing_time = time.time() - start_time
            return faces, float(processing_time)
            
        except Exception as e:
            logger.error(f"âŒ YOLO ì–¼êµ´ ê²€ì¶œ ì˜¤ë¥˜: {e}")
            return [], float(time.time() - start_time)
    
    def extract_face_embedding(self, image: np.ndarray, face_bbox: List[int]) -> np.ndarray:
        """FaceNetìœ¼ë¡œ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ"""
        if self.facenet_model is None:
            return np.array([])
        
        try:
            x, y, w, h = face_bbox
            
            # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
            face_region = image[y:y+h, x:x+w]
            if face_region.size == 0:
                return np.array([])
            
            # BGR -> RGB ë³€í™˜
            face_rgb = cv2.cvtColor(face_region, cv2.COLOR_BGR2RGB)
            face_pil = Image.fromarray(face_rgb)
            
            # ì „ì²˜ë¦¬
            face_tensor = self.transform(face_pil).unsqueeze(0).to(self.device)
            
            # FaceNet ì„ë² ë”© ì¶”ì¶œ
            with torch.no_grad():
                embedding = self.facenet_model(face_tensor)
                embedding = embedding.cpu().numpy().flatten()
            
            return embedding
            
        except Exception as e:
            logger.error(f"âŒ FaceNet ì„ë² ë”© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return np.array([])
    
    def load_user_database(self, users_dir: str = "data/users"):
        """ì‚¬ìš©ì ì–¼êµ´ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        try:
            if not os.path.exists(users_dir):
                logger.warning(f"ì‚¬ìš©ì ë°ì´í„° í´ë” ì—†ìŒ: {users_dir}")
                return
            
            self.user_embeddings = {}
            self.user_names = []
            
            for user_name in os.listdir(users_dir):
                user_path = os.path.join(users_dir, user_name)
                
                if os.path.isdir(user_path):
                    logger.info(f"ğŸ“„ {user_name} ë°ì´í„° ë¡œë“œ ì¤‘...")
                    
                    user_embeddings_list = []
                    processed_count = 0
                    
                    for image_file in os.listdir(user_path):
                        if image_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                            image_path = os.path.join(user_path, image_file)
                            
                            try:
                                # ì´ë¯¸ì§€ ë¡œë“œ
                                image = cv2.imread(image_path)
                                if image is None:
                                    continue
                                
                                # ì–¼êµ´ ê²€ì¶œ
                                faces, _ = self.detect_faces(image)
                                
                                if faces:
                                    # ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
                                    largest_face = max(faces, key=lambda x: x['area'])
                                    
                                    # FaceNet ì„ë² ë”© ì¶”ì¶œ
                                    embedding = self.extract_face_embedding(image, largest_face['bbox'])
                                    
                                    if len(embedding) > 0:
                                        user_embeddings_list.append(embedding)
                                        processed_count += 1
                                        
                            except Exception as e:
                                logger.warning(f"âš ï¸ {image_file} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                                continue
                    
                    if user_embeddings_list:
                        self.user_embeddings[user_name] = user_embeddings_list
                        self.user_names.append(user_name)
                        logger.info(f"âœ… {user_name}: {processed_count}ì¥ ì²˜ë¦¬ ì™„ë£Œ")
                    else:
                        logger.warning(f"âš ï¸ {user_name}: ì²˜ë¦¬ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ì—†ìŒ")
            
            logger.info(f"ğŸ¯ ì´ {len(self.user_names)}ëª…ì˜ ì‚¬ìš©ì ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            
            # ì„ë² ë”© ë°ì´í„° ì €ì¥
            self.save_embeddings()
            
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def save_embeddings(self, save_path: str = "data/facenet_embeddings.pkl"):
        """ì„ë² ë”© ë°ì´í„° ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            with open(save_path, 'wb') as f:
                pickle.dump({
                    'user_embeddings': self.user_embeddings,
                    'user_names': self.user_names
                }, f)
            logger.info(f"ğŸ’¾ ì„ë² ë”© ë°ì´í„° ì €ì¥: {save_path}")
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_embeddings(self, load_path: str = "data/facenet_embeddings.pkl"):
        """ì„ë² ë”© ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists(load_path):
                with open(load_path, 'rb') as f:
                    data = pickle.load(f)
                self.user_embeddings = data['user_embeddings']
                self.user_names = data['user_names']
                logger.info(f"ğŸ“‚ ì„ë² ë”© ë°ì´í„° ë¡œë“œ: {len(self.user_names)}ëª…")
                return True
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False
    
    def recognize_user(self, face_embedding: np.ndarray, threshold: float = 0.6) -> Dict:
        """FaceNet ì„ë² ë”©ìœ¼ë¡œ ì‚¬ìš©ì ì¸ì‹"""
        if len(self.user_embeddings) == 0:
            return {
                'recognized': False,
                'user_name': 'ë°ì´í„°ë² ì´ìŠ¤ ì—†ìŒ',
                'confidence': 0.0,
                'distance': 999.0,
                'message': 'ë“±ë¡ëœ ì‚¬ìš©ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'
            }
        
        if len(face_embedding) == 0:
            return {
                'recognized': False,
                'user_name': 'íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨',
                'confidence': 0.0,
                'distance': 999.0,
                'message': 'ì–¼êµ´ íŠ¹ì§•ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'
            }
        
        try:
            best_distance = float('inf')
            best_user = None
            all_distances = {}
            
            # ê° ì‚¬ìš©ìì™€ì˜ ê±°ë¦¬ ê³„ì‚°
            for user_name, embeddings_list in self.user_embeddings.items():
                user_distances = []
                
                for stored_embedding in embeddings_list:
                    # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
                    distance = np.linalg.norm(face_embedding - stored_embedding)
                    user_distances.append(distance)
                
                # í•´ë‹¹ ì‚¬ìš©ìì˜ ìµœì†Œ ê±°ë¦¬ (ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ì§„)
                min_distance = min(user_distances)
                all_distances[user_name] = min_distance
                
                if min_distance < best_distance:
                    best_distance = min_distance
                    best_user = user_name
            
            # ì‹ ë¢°ë„ ê³„ì‚° (ê±°ë¦¬ë¥¼ ë°±ë¶„ìœ¨ë¡œ ë³€í™˜)
            confidence = max(0, (1 - best_distance) * 100)
            
            # ì„ê³„ê°’ í™•ì¸
            if best_distance < threshold and best_user is not None:
                return {
                    'recognized': True,
                    'user_name': str(best_user),
                    'confidence': float(round(confidence, 2)),
                    'distance': float(round(best_distance, 4)),
                    'threshold': float(threshold),
                    'all_distances': {k: float(round(v, 4)) for k, v in all_distances.items()},
                    'message': f'{best_user} ì¸ì‹ ì„±ê³µ'
                }
            else:
                return {
                    'recognized': False,
                    'user_name': 'ë¯¸ë“±ë¡ ì¸ë¬¼',
                    'confidence': float(round(confidence, 2)),
                    'distance': float(round(best_distance, 4)),
                    'threshold': float(threshold),
                    'best_match': str(best_user) if best_user else 'ë§¤ì¹­ ì—†ìŒ',
                    'all_distances': {k: float(round(v, 4)) for k, v in all_distances.items()},
                    'message': f'ê±°ë¦¬ {round(best_distance, 4)} > í—ˆìš©ê°’ {threshold}'
                }
                
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ì¸ì‹ ì˜¤ë¥˜: {e}")
            return {
                'recognized': False,
                'user_name': 'ì¸ì‹ ì˜¤ë¥˜',
                'confidence': 0.0,
                'distance': 999.0,
                'message': f'ì¸ì‹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }
    
    def process_image(self, image: np.ndarray) -> Dict:
        """
        ì „ì²´ ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        1. YOLOv8-Faceë¡œ ì–¼êµ´ ê²€ì¶œ
        2. FaceNetìœ¼ë¡œ ì„ë² ë”© ì¶”ì¶œ ë° ì¸ì‹
        """
        start_time = time.time()
        
        try:
            # 1. ì–¼êµ´ ê²€ì¶œ
            faces, detection_time = self.detect_faces(image)
            
            if not faces:
                return {
                    'success': False,
                    'faces_found': 0,
                    'message': 'ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
                    'performance': {
                        'detection_time': float(round(detection_time, 3)),
                        'total_time': float(round(time.time() - start_time, 3))
                    }
                }
            
            # 2. ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
            main_face = faces[0]
            
            # 3. FaceNet ì„ë² ë”© ì¶”ì¶œ
            embedding_start = time.time()
            face_embedding = self.extract_face_embedding(image, main_face['bbox'])
            embedding_time = time.time() - embedding_start
            
            # 4. ì‚¬ìš©ì ì¸ì‹
            recognition_start = time.time()
            recognition_result = self.recognize_user(face_embedding)
            recognition_time = time.time() - recognition_start
            
            total_time = time.time() - start_time
            
            # ê²°ê³¼ í†µí•©
            result = {
                'success': True,
                'faces_found': int(len(faces)),
                'main_face': {
                    **main_face,
                    **recognition_result
                },
                'all_faces': faces,
                'performance': {
                    'detection_time': float(round(detection_time, 3)),
                    'embedding_time': float(round(embedding_time, 3)),
                    'recognition_time': float(round(recognition_time, 3)),
                    'total_time': float(round(total_time, 3))
                },
                'method': 'yolov8_facenet',
                'embedding_size': len(face_embedding)
            }
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                'success': False,
                'faces_found': 0,
                'message': f'ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}',
                'performance': {
                    'total_time': float(round(time.time() - start_time, 3))
                }
            }
    
    def get_model_info(self) -> Dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            'system_type': 'yolov8_facenet',
            'detection_model': 'YOLOv8-Face',
            'recognition_model': 'FaceNet (512D)',
            'device': self.device,
            'confidence_threshold': self.confidence_threshold,
            'iou_threshold': self.iou_threshold,
            'registered_users_count': len(self.user_names),
            'registered_users': self.user_names,
            'model_loaded': self.yolo_model is not None and self.facenet_model is not None,
            'yolo_loaded': self.yolo_model is not None,
            'facenet_loaded': self.facenet_model is not None,
            'embedding_dimension': 512
        }